{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7zSSeX21Grj"
      },
      "source": [
        "# Simple iteration for systems of linear equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRz8VJ0N1Grn"
      },
      "source": [
        "First, generate a random diagonally dominant matrix, for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "jTVkb-WZ1Gro"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rndm = np.random.RandomState(1234)\n",
        "\n",
        "n = 10\n",
        "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
        "b = rndm.uniform(size=n)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "id": "4mv5q-nMKZwY",
        "outputId": "532fa7cf-63ac-45e1-d3d3-a651c75ef360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.51915195e+01, 6.22108771e-01, 4.37727739e-01, 7.85358584e-01,\n",
              "        7.79975808e-01, 2.72592605e-01, 2.76464255e-01, 8.01872178e-01,\n",
              "        9.58139354e-01, 8.75932635e-01],\n",
              "       [3.57817270e-01, 1.55009951e+01, 6.83462935e-01, 7.12702027e-01,\n",
              "        3.70250755e-01, 5.61196186e-01, 5.03083165e-01, 1.37684496e-02,\n",
              "        7.72826622e-01, 8.82641191e-01],\n",
              "       [3.64885984e-01, 6.15396178e-01, 1.50753812e+01, 3.68824006e-01,\n",
              "        9.33140102e-01, 6.51378143e-01, 3.97202578e-01, 7.88730143e-01,\n",
              "        3.16836122e-01, 5.68098653e-01],\n",
              "       [8.69127390e-01, 4.36173424e-01, 8.02147642e-01, 1.51437668e+01,\n",
              "        7.04260971e-01, 7.04581308e-01, 2.18792106e-01, 9.24867629e-01,\n",
              "        4.42140755e-01, 9.09315959e-01],\n",
              "       [5.98092228e-02, 1.84287084e-01, 4.73552788e-02, 6.74880944e-01,\n",
              "        1.55946248e+01, 5.33310163e-01, 4.33240627e-02, 5.61433080e-01,\n",
              "        3.29668446e-01, 5.02966833e-01],\n",
              "       [1.11894318e-01, 6.07193706e-01, 5.65944643e-01, 6.76406199e-03,\n",
              "        6.17441709e-01, 1.59121229e+01, 7.90524133e-01, 9.92081466e-01,\n",
              "        9.58801762e-01, 7.91964135e-01],\n",
              "       [2.85250960e-01, 6.24916705e-01, 4.78093796e-01, 1.95675179e-01,\n",
              "        3.82317452e-01, 5.38736851e-02, 1.54516484e+01, 9.82004742e-01,\n",
              "        1.23942700e-01, 1.19380898e-01],\n",
              "       [7.38523056e-01, 5.87303633e-01, 4.71632534e-01, 1.07126817e-01,\n",
              "        2.29218565e-01, 8.99965195e-01, 4.16753538e-01, 1.55358517e+01,\n",
              "        6.20851659e-03, 3.00641706e-01],\n",
              "       [4.36893172e-01, 6.12148997e-01, 9.18198075e-01, 6.25736670e-01,\n",
              "        7.05997565e-01, 1.49833716e-01, 7.46063409e-01, 8.31006992e-01,\n",
              "        1.56337258e+01, 4.38309881e-01],\n",
              "       [1.52572775e-01, 5.68409615e-01, 5.28224278e-01, 9.51428764e-01,\n",
              "        4.80359179e-01, 5.02559563e-01, 5.36878193e-01, 8.19202067e-01,\n",
              "        5.71156381e-02, 1.56694217e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNGIGBex1Grq"
      },
      "source": [
        "# I.  Jacobi iteration\n",
        "\n",
        "Given\n",
        "\n",
        "$$\n",
        "A x = b\n",
        "$$\n",
        "\n",
        "separate the diagonal part $D$,\n",
        "\n",
        "$$ A = D + (A - D) $$\n",
        "\n",
        "and write\n",
        "\n",
        "$$\n",
        "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
        "$$\n",
        "\n",
        "Then iterate\n",
        "\n",
        "$$\n",
        "x_{n + 1} = B x_{n} + c\\;,\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$$\n",
        "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB2PHHIK1Grr"
      },
      "source": [
        "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bnk796g61Grr"
      },
      "outputs": [],
      "source": [
        "diag_1d = np.diag(A)\n",
        "\n",
        "B = -A.copy()\n",
        "np.fill_diagonal(B, 0)\n",
        "\n",
        "D = np.diag(diag_1d)\n",
        "invD = np.diag(1./diag_1d)\n",
        "BB = invD @ B \n",
        "c = invD @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0NTUyC3i1Grs"
      },
      "outputs": [],
      "source": [
        "# sanity checks\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "assert_allclose(-B + D, A)\n",
        "\n",
        "\n",
        "# xx is a \"ground truth\" solution, compute it using a direct method\n",
        "xx = np.linalg.solve(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@xx, b)\n",
        "np.testing.assert_allclose(D@xx, B@xx + b)\n",
        "np.testing.assert_allclose(xx, BB@xx + c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRaVUE6U1Grt"
      },
      "source": [
        "Check that $\\| B\\| \\leqslant 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zgED2OGu1Gru",
        "outputId": "685cde91-68e3-4fe6-b029-f9136b8faf0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36436161983015336"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "np.linalg.norm(BB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBcusqg1Grv"
      },
      "source": [
        "### Do the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "NK6iwDtm1Grv"
      },
      "outputs": [],
      "source": [
        "n_iter = 50\n",
        "\n",
        "x0 = np.ones(n)\n",
        "x = x0\n",
        "for _ in range(n_iter):\n",
        "    x = BB @ x + c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gsLyio7W1Grw",
        "outputId": "6782c608-b646-426a-e8ca-5669e67f3d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
              "        1.11022302e-16,  0.00000000e+00, -2.42861287e-17,  0.00000000e+00,\n",
              "       -2.77555756e-17,  1.11022302e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check the result:\n",
        "\n",
        "A @ x - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXfb9BuT1Grw"
      },
      "source": [
        "### Task I.1\n",
        "\n",
        "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
        "\n",
        "\n",
        "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
        "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
        "\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "5zqTUVVa1Grw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def jacobi_iteration(A, b, num_iterations):\n",
        "    n = len(A)\n",
        "    x = np.zeros(n)\n",
        "    x_new = np.zeros(n)\n",
        "    \n",
        "    for _ in range(num_iterations):\n",
        "        for i in range(n):\n",
        "            x_new[i] = (b[i] - np.dot(A[i, :i], x[:i]) - np.dot(A[i, i+1:], x[i+1:])) / A[i, i]\n",
        "        x = x_new.copy()\n",
        "        \n",
        "        B = np.matmul(A, x) - b\n",
        "        norm_B = norm(B)\n",
        "        print(f\"Iteration {_+1}: Norm of B = {norm_B}\")\n",
        "    \n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[10, 2, 1],\n",
        "              [1, 5, 1],\n",
        "              [2, 3, 10]])\n",
        "b = np.array([7, -8, 6])\n",
        "num_iterations = 10\n",
        "\n",
        "result = jacobi_iteration(A, b, num_iterations)\n",
        "print(\"Final result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7olL_pYqV1Cc",
        "outputId": "b566e5d8-efdc-453f-c2fe-cfc75bdd1c4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Norm of B = 4.4732538492690095\n",
            "Iteration 2: Norm of B = 0.6782329983125271\n",
            "Iteration 3: Norm of B = 0.39077870975783685\n",
            "Iteration 4: Norm of B = 0.05815874826713564\n",
            "Iteration 5: Norm of B = 0.04228448415199155\n",
            "Iteration 6: Norm of B = 0.009958895521090685\n",
            "Iteration 7: Norm of B = 0.005483374625174072\n",
            "Iteration 8: Norm of B = 0.0017266477783258476\n",
            "Iteration 9: Norm of B = 0.0007873061769432243\n",
            "Iteration 10: Norm of B = 0.0002823592107246779\n",
            "Final result: [ 1.00001027 -1.99998396  1.00001466]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBnguRFT1Grx"
      },
      "source": [
        "# II. Seidel's iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSbuFdYU1Grx"
      },
      "source": [
        "##### Task II.1\n",
        "\n",
        "Implement the Seidel's iteration. \n",
        "\n",
        "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "FYygs3Ml1Grx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def gauss_seidel_iteration(A, b, num_iterations):\n",
        "    n = len(A)\n",
        "    x = np.zeros(n)\n",
        "    \n",
        "    for _ in range(num_iterations):\n",
        "        for i in range(n):\n",
        "            x[i] = (b[i] - np.dot(A[i, :i], x[:i]) - np.dot(A[i, i+1:], x[i+1:])) / A[i, i]\n",
        "    \n",
        "        B = np.matmul(A, x) - b\n",
        "        norm_B = norm(B)\n",
        "        print(f\"Iteration {_+1}: Norm of B = {norm_B}\")\n",
        "    \n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5  # Size of the matrix\n",
        "A = np.random.rand(n, n)\n",
        "b = np.random.rand(n)\n",
        "num_iterations = 10\n",
        "\n",
        "result = gauss_seidel_iteration(A, b, num_iterations)\n",
        "print(\"Final result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdCpaQ9KXANP",
        "outputId": "b433c0e4-24ee-4f33-8c06-f7a7eb57f53b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Norm of B = 202.67938024009368\n",
            "Iteration 2: Norm of B = 20189.717851304937\n",
            "Iteration 3: Norm of B = 1952569.1733999238\n",
            "Iteration 4: Norm of B = 188604789.47848713\n",
            "Iteration 5: Norm of B = 18217253146.44172\n",
            "Iteration 6: Norm of B = 1759594014229.8066\n",
            "Iteration 7: Norm of B = 169958167388565.2\n",
            "Iteration 8: Norm of B = 1.6416160991365828e+16\n",
            "Iteration 9: Norm of B = 1.585627485995254e+18\n",
            "Iteration 10: Norm of B = 1.5315484087062138e+20\n",
            "Final result: [-3.61900703e+18  1.04874310e+18  2.28794796e+18 -1.13800780e+20\n",
            "  4.11944927e+18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3PDxY8W1Gry"
      },
      "source": [
        "# III. Minimum residual scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbfUD6zy1Gry"
      },
      "source": [
        " ### Task III.1\n",
        "\n",
        "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
        "\n",
        "(50% of the grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "60_IGETi1Gry"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm, solve\n",
        "\n",
        "\n",
        "def minres(A, b, num_iterations):\n",
        "    n = len(A)\n",
        "    x = np.zeros(n)\n",
        "    r = b - np.dot(A, x)\n",
        "    p = r.copy()\n",
        "    norm_b = norm(b)\n",
        "    \n",
        "    for k in range(num_iterations):\n",
        "        Ap = np.dot(A, p)\n",
        "        alpha = np.dot(r, r) / np.dot(p, Ap)\n",
        "        x += alpha * p\n",
        "        r -= alpha * Ap\n",
        "        \n",
        "        residual_norm = norm(r)\n",
        "        deviation = norm(x - solve(A, b))\n",
        "        tau = np.dot(r, Ap) / np.dot(Ap, Ap)\n",
        "        \n",
        "        print(f\"Iteration {k+1}: Residual Norm = {residual_norm}, Deviation = {deviation}, Tau = {tau}\")\n",
        "        \n",
        "        if residual_norm / norm_b < 1e-6:\n",
        "            break\n",
        "        \n",
        "        beta = np.dot(r, r) / np.dot(Ap, Ap)\n",
        "        p = r + beta * p\n",
        "    \n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5  # Size of the matrix\n",
        "A = np.random.rand(n, n)\n",
        "b = np.random.rand(n)\n",
        "num_iterations = 10\n",
        "\n",
        "result = minres(A, b, num_iterations)\n",
        "print(\"Final result:\", result)"
      ],
      "metadata": {
        "id": "VSMqH05qXK1A",
        "outputId": "7e8565e4-2e2c-428c-8b95-53ff02aa93dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Residual Norm = 0.7869451337170505, Deviation = 3.4847854124617377, Tau = -0.20350339387417132\n",
            "Iteration 2: Residual Norm = 0.6399674937213871, Deviation = 2.8870746505007157, Tau = -0.4273764881607348\n",
            "Iteration 3: Residual Norm = 0.36084513067062746, Deviation = 2.6252614236409353, Tau = -0.234075781277884\n",
            "Iteration 4: Residual Norm = 0.38883749239363674, Deviation = 2.633208942059029, Tau = -0.4720014191894415\n",
            "Iteration 5: Residual Norm = 1.3460004577566667, Deviation = 3.5685548248093997, Tau = -2.9223482403616656\n",
            "Iteration 6: Residual Norm = 0.7556228810943256, Deviation = 2.1468624044984668, Tau = -0.0884163522613723\n",
            "Iteration 7: Residual Norm = 0.3211150040673144, Deviation = 2.293470627236445, Tau = -0.1354987474229064\n",
            "Iteration 8: Residual Norm = 0.4633179436232935, Deviation = 2.538169855052374, Tau = -0.7789915746096282\n",
            "Iteration 9: Residual Norm = 8.228684845345434, Deviation = 10.03004038206825, Tau = -14.138258065484017\n",
            "Iteration 10: Residual Norm = 0.49272329284918, Deviation = 1.7917270949210866, Tau = -0.0043052326245684395\n",
            "Final result: [-1.11646741  2.15159261  0.17399688  0.10926121  0.03810603]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}